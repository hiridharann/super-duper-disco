import streamlit as st
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from supabase import create_client, Client, ClientOptions
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

# --- Page Config ---
st.set_page_config(page_title="Qwen Chat", page_icon="ðŸš„")

# --- Custom Storage for the "Amnesia" Bug ---
class DictStorage:
    def __init__(self):
        self.data = {}
    def get_item(self, key):
        return self.data.get(key)
    def set_item(self, key, value):
        self.data[key] = value
    def remove_item(self, key):
        self.data.pop(key, None)

# --- 1. Database & Auth Setup ---
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    REDIRECT_URL = st.secrets["REDIRECT_URL"]
    
    # We use our custom storage to catch the secrets
    storage = DictStorage()
    supabase: Client = create_client(
        SUPABASE_URL, 
        SUPABASE_KEY, 
        options=ClientOptions(storage=storage)
    )
except Exception as e:
    st.error("Secrets missing! Check .streamlit/secrets.toml")
    st.stop()

# --- 2. Auth Logic (The Fix) ---
if "session" not in st.session_state:
    st.session_state.session = None

# Handle Return from Google
if "code" in st.query_params:
    try:
        code = st.query_params["code"]
        verifier = st.query_params.get("verifier") # Retrieve the secret key from URL
        
        if verifier:
            # Restore the secret key into Supabase's memory
            # We find the internal key name usually ending in 'code-verifier'
            storage.set_item("supabase.auth.token-code-verifier", verifier)
        
        session = supabase.auth.exchange_code_for_session({"auth_code": code})
        st.session_state.session = session
        st.query_params.clear()
        st.rerun()
    except Exception as e:
        st.error(f"Login failed: {e}")

user = st.session_state.session.user if st.session_state.session else None

# --- 3. Login Screen ---
if not user:
    st.title("ðŸš„ Qwen 2.5 Login")
    st.write("Please sign in to access the AI.")
    
    try:
        # 1. Generate the Google URL
        data = supabase.auth.sign_in_with_oauth({
            "provider": "google",
            "options": {"redirect_to": REDIRECT_URL}
        })
        
        # 2. THE FIX: Extract the Secret Key (Verifier)
        # We look inside our custom storage to find the key generated by Supabase
        verifier = next((v for k, v in storage.data.items() if k.endswith("code-verifier")), None)
        
        # 3. Attach it to the Redirect URL so it survives the trip
        if verifier:
            # We modify the 'redirect_to' param inside the generated URL
            # This makes Supabase send the verifier back to us in the URL
            parsed_url = urlparse(data.url)
            params = parse_qs(parsed_url.query)
            
            # Add verifier to our specialized Redirect URL
            new_redirect = f"{REDIRECT_URL}?verifier={verifier}"
            params["redirect_to"] = new_redirect
            
            # Rebuild the full Google URL
            new_query = urlencode(params, doseq=True)
            final_url = urlunparse(parsed_url._replace(query=new_query))
        else:
            final_url = data.url

        st.link_button("Sign in with Google", final_url, type="primary")
        
    except Exception as e:
        st.error(f"Auth Error: {e}")
    st.stop()

# --- 4. Main App (Logged In) ---
st.sidebar.success(f"User: {user.email}")
if st.sidebar.button("Logout"):
    supabase.auth.sign_out()
    st.session_state.session = None
    st.rerun()

st.title("ðŸš„ Qwen 2.5 0.5B-Instruct")

# --- Load Model (Cached) ---
@st.cache_resource
def load_model():
    model_id = "Qwen/Qwen2.5-0.5B-Instruct"
    with st.spinner("Downloading Qwen..."):
        tokenizer = AutoTokenizer.from_pretrained(model_id)
        model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.float32,
            device_map="cpu",
            low_cpu_mem_usage=True
        )
    return tokenizer, model

try:
    tokenizer, model = load_model()
except Exception as e:
    st.error(f"Model Error: {e}")
    st.stop()

# --- Chat Logic ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Ask Qwen..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        chat_history = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
        text = tokenizer.apply_chat_template(chat_history, tokenize=False, add_generation_prompt=True)
        inputs = tokenizer([text], return_tensors="pt").to(model.device)

        with st.spinner("Thinking..."):
            outputs = model.generate(
                **inputs,
                max_new_tokens=512,
                temperature=0.7,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )
        response_tokens = outputs[0][len(inputs.input_ids[0]):]
        full_response = tokenizer.decode(response_tokens, skip_special_tokens=True)
        response_placeholder.markdown(full_response)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # Log to Supabase
    try:
        supabase.table("chat_logs").insert({
            "user_id": user.id,
            "email": user.email,
            "user_msg": prompt,
            "ai_msg": full_response,
            "model": "Qwen-0.5B"
        }).execute()
    except Exception as e:
        print(f"DB Log Error: {e}")
